{"version":3,"sources":["utils/TextToSpeech.js","utils/SpeechToText.js","App.js","index.js"],"names":["onHandleSpeak","textToRead","available_voices","window","speechSynthesis","getVoices","english_voice","i","length","lang","utter","SpeechSynthesisUtterance","rate","pitch","text","voice","speak","recognition","SpeechRecognition","webkitSpeechRecognition","continous","interimResults","noteContent","recognizing","onstart","onend","onerror","event","SpeechToText","useState","listenToSpeaker","setListenToSpeaker","speechText","useRef","useEffect","stop","handleListen","current","value","start","onresult","resultIndex","transcript","results","style","height","width","ref","onClick","disabled","App","setTextToRead","className","onChange","e","target","ReactDOM","render","document","getElementById"],"mappings":"sLAkCeA,EAlCO,SAACC,GASrB,IAPA,IAAIC,EAAmBC,OAAOC,gBAAgBC,YAG1CC,EAAgB,GAIZC,EAAE,EAAGA,EAAEL,EAAiBM,OAAQD,IACtC,GAAgC,UAA7BL,EAAiBK,GAAGE,KAAkB,CACvCH,EAAgBJ,EAAiBK,GACjC,MAGiB,KAAlBD,IACDA,EAAgBJ,EAAiB,IAGnC,IAAIQ,EAAQ,IAAIC,yBAChBD,EAAME,KAAO,GACbF,EAAMG,MAAQ,GACdH,EAAMI,KAAOb,EACbS,EAAMK,MAAQT,EAQdH,OAAOC,gBAAgBY,MAAMN,IC5BzBO,EAAc,IADMd,OAAOe,mBAAqBf,OAAOgB,yBAG7DF,EAAYG,WAAY,EACxBH,EAAYI,gBAAiB,EAG7B,IAAIC,EAAc,GACdC,GAAc,EAClBN,EAAYO,QAAU,WACpBD,GAAc,GAGhBN,EAAYQ,MAAQ,WAClBF,GAAc,GAGhBN,EAAYS,QAAU,SAAUC,GAC9BJ,GAAc,GAGhB,IAwDeK,EAxDM,WAAO,IAAD,EACqBC,oBAAS,GAD9B,mBAClBC,EADkB,KACDC,EADC,KAEnBC,EAAaC,iBAAO,MAU1BC,qBAAU,WACRjB,EAAYkB,OACZC,MACC,CAACN,IAEJ,IAAMM,EAAe,WACfN,GACFE,EAAWK,QAAQC,MAAQ,GACtBf,GAAaN,EAAYsB,QAC9BtB,EAAYQ,MAAQ,kBAAMR,EAAYsB,UAEtCtB,EAAYkB,OAGdlB,EAAYuB,SAAW,SAAAb,GACrB,IAAMU,EAAUV,EAAMc,YAClBC,EAAaf,EAAMgB,QAAQN,GAAS,GAAGK,WAEN,IAAZL,GAAiBK,IAAef,EAAMgB,QAAQ,GAAG,GAAGD,aAG3EpB,EAAcoB,EACdV,EAAWK,QAAQC,MAAQhB,KAMjC,OACE,oCACE,8BACEsB,MAAO,CAAEC,OAAQ,QAASC,MAAO,SACjCC,IAAKf,IAEP,4BAAQgB,QAAS,WAzCnBjB,GAAmB,IAyCgBkB,SAAUnB,GAA3C,QAGA,4BAAQkB,QAAS,WAxCnBjB,GAAmB,IAwCckB,UAAWnB,GAA1C,UClDSoB,MAlBf,WAAgB,IAAD,EACuBrB,mBAAS,IADhC,mBACN5B,EADM,KACMkD,EADN,KAGb,OACE,yBAAKC,UAAU,OACb,2BACEd,MAAOrC,EACPoD,SAAU,SAACC,GAAD,OAAOH,EAAcG,EAAEC,OAAOjB,UAE1C,4BAAQU,QAAS,kBAAMhD,EAAcC,KAArC,SAGA,6BACA,kBAAC,EAAD,QCbNuD,IAASC,OAAO,kBAAC,EAAD,MAASC,SAASC,eAAe,W","file":"static/js/main.286c2609.chunk.js","sourcesContent":["const onHandleSpeak = (textToRead) => {\n  // get all voices that browser offers\n  let available_voices = window.speechSynthesis.getVoices();\n\n  // this will hold an english voice\n  let english_voice = '';\n\n  // find voice by language locale \"en-US\"\n  // if not then select the first voice\n  for(var i=0; i<available_voices.length; i++) {\n    if(available_voices[i].lang === 'en-US') {\n      english_voice = available_voices[i];\n      break;\n    }\n  }\n  if(english_voice === '')\n    english_voice = available_voices[0];\n\n  // new SpeechSynthesisUtterance object\n  var utter = new SpeechSynthesisUtterance();\n  utter.rate = 0.6;\n  utter.pitch = 0.5;\n  utter.text = textToRead;\n  utter.voice = english_voice;\n\n  // event after text has been spoken\n  // utter.onend = function() {\n  //   alert('Speech has finished');\n  // }\n\n  // speak\n  window.speechSynthesis.speak(utter);\n}\n\nexport default onHandleSpeak","import React, { useState, useEffect, useRef } from 'react'\n\nconst SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition\nconst recognition = new SpeechRecognition()\n\nrecognition.continous = true\nrecognition.interimResults = true\n// recognition.lang = 'en-US'\n\nlet noteContent = \"\"\nlet recognizing = false\nrecognition.onstart = function () {\n  recognizing = true\n}\n\nrecognition.onend = function () {\n  recognizing = false\n}\n\nrecognition.onerror = function (event) {\n  recognizing = false\n}\n\nconst SpeechToText = () => {\n  const [listenToSpeaker, setListenToSpeaker] = useState(false)\n  const speechText = useRef(null)\n\n  const Listen = () => {\n    setListenToSpeaker(true)\n  }\n\n  const Stop = () => {\n    setListenToSpeaker(false)\n  }\n\n  useEffect(() => {\n    recognition.stop()\n    handleListen()\n  }, [listenToSpeaker])\n\n  const handleListen = () => {\n    if (listenToSpeaker) {\n      speechText.current.value = \"\"\n      if (!recognizing) recognition.start()\n      recognition.onend = () => recognition.start()\n    } else {\n      recognition.stop()\n    }\n\n    recognition.onresult = event => {\n      const current = event.resultIndex\n      let transcript = event.results[current][0].transcript\n\n      const mobileRepeatBug = (current === 1 && transcript === event.results[0][0].transcript)\n\n      if(!mobileRepeatBug) {\n        noteContent = transcript\n        speechText.current.value = noteContent\n      }\n    }\n    // console.log(transcript)\n  }\n\n  return (\n    <>\n      <textarea\n        style={{ height: '300px', width: '300px'}}\n        ref={speechText}\n      />\n      <button onClick={() => Listen()} disabled={listenToSpeaker}>\n        Talk\n      </button>\n      <button onClick={() => Stop()} disabled={!listenToSpeaker}>\n        Stop\n      </button>\n    </>\n  )\n}\n\nexport default SpeechToText","import React, { useState } from 'react';\nimport onHandleSpeak from './utils/TextToSpeech'\nimport SpeechToText from './utils/SpeechToText'\n\nfunction App() {\n  const [textToRead, setTextToRead] = useState(\"\")\n\n  return (\n    <div className=\"App\">\n      <input\n        value={textToRead}\n        onChange={(e) => setTextToRead(e.target.value)}\n      />\n      <button onClick={() => onHandleSpeak(textToRead)}>\n        Speak\n      </button>\n      <br/>\n      <SpeechToText/>\n    </div>\n  );\n}\n\nexport default App;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport App from './App';\n\nReactDOM.render(<App />, document.getElementById('root'));\n"],"sourceRoot":""}